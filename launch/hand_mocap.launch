<launch>
  <arg name="camera_type" default="realsense" /> <!-- kinect, realsense, astra -->
  <arg name="device" default="cuda:0" /> <!-- cpu or cuda -->

  <arg name="with_mocap" default="true" />
  <arg name="detector_model" default="yolo_hand" />  <!-- hand_object_detector, mediapipe_hand, yolo_hand, ... -->
  <arg name="mocap_model" default="wilor" />  <!-- frankmocap_hand, hamer, 4d-human, wilor -->
  <arg name="render_type" default="opengl" />  <!-- for frankmocap, opengl or pytorch3d -->
  <arg name="rescale_factor" default="2.0" />  <!-- for hamer -->
  <arg name="threshold" default="0.9" />
  <arg name="depth_scale" default="0.001" /> <!-- scale for depth format, depends on camera device -->
  <arg name="margin" default="10" /> <!-- hand bounding box margin -->

  <arg name="publish_tf" default="true" />
  <arg name="visualize" default="true" /> <!-- visualization. set false if you want to speed up -->

  <arg name="wrist_a" default="0.03" /> <!-- length of cross section ellipse of the wrist (meter) -->
  <arg name="wrist_b" default="0.0225" />
  <arg name="arrow" default="true" /> <!-- visualize arrow for tip direction -->

  <group if="$(eval camera_type == 'kinect')">
    <arg name="input_image" default="/kinect_head/rgb/image_rect_color"/>
    <arg name="input_depth" default="/kinect_head/depth_registered/image_rect"/>
    <arg name="camera_info" default="/kinect_head/rgb/camera_info"/>

    <arg name="decompress" default="false" />
    <arg name="_input_image" value="$(arg input_image)" unless="$(arg decompress)" />
    <arg name="_input_image" value="/detection_node/input_image" if="$(arg decompress)" />
    <!-- Image Decompress -->
    <node name="image_decompresser"
        pkg="image_transport" type="republish"
        args="compressed raw" respawn="true" if="$(arg decompress)">
    <remap from="in" to="$(arg input_image)"/>
    <remap from="out" to="$(arg _input_image)"/>
    </node>

    <!-- hand_detection node -->
    <node name="detection_node"
        pkg="mocap_ros" type="detection_node.py"
        output="screen" >
    <remap from="~input_image" to="$(arg _input_image)" />
    <remap from="~input_depth" to="$(arg input_depth)" />
    <remap from="~camera_info" to="$(arg camera_info)" />
    <rosparam subst_value="true" >
        device: $(arg device)
        publish_tf: $(arg publish_tf)
        threshold: $(arg threshold)
        with_mocap: $(arg with_mocap)
        detector_model: $(arg detector_model)
        mocap_model: $(arg mocap_model)
        visualize: $(arg visualize)
        render_type: $(arg render_type)
        rescale_factor: $(arg rescale_factor)
        margin: $(arg margin)
        scale: $(arg depth_scale)
        wrist_a: $(arg wrist_a)
        wrist_b: $(arg wrist_b)
    </rosparam>
    </node>
  </group>

  <group if="$(eval camera_type == 'realsense')">
    <arg name="input_image" default="/camera/color/image_rect_color"/>
    <arg name="input_depth" default="/camera/aligned_depth_to_color/image_raw"/>
    <arg name="camera_info" default="/camera/color/camera_info"/>
    <!-- hand_detection node -->
    <node name="detection_node"
        pkg="mocap_ros" type="detection_node.py"
        output="screen" >
    <remap from="~input_image" to="$(arg input_image)" />
    <remap from="~input_depth" to="$(arg input_depth)" />
    <remap from="~camera_info" to="$(arg camera_info)" />
    <rosparam subst_value="true" >
        device: $(arg device)
        publish_tf: $(arg publish_tf)
        threshold: $(arg threshold)
        with_mocap: $(arg with_mocap)
        detector_model: $(arg detector_model)
        mocap_model: $(arg mocap_model)
        visualize: $(arg visualize)
        render_type: $(arg render_type)
        rescale_factor: $(arg rescale_factor)
        margin: $(arg margin)
        scale: $(arg depth_scale)
        wrist_a: $(arg wrist_a)
        wrist_b: $(arg wrist_b)
    </rosparam>
    </node>
  </group>

  <group if="$(eval camera_type == 'astra')">
    <arg name="input_image" default="/camera/color/image_raw"/>
    <arg name="input_depth" default="/camera/depth/image_raw"/>
    <arg name="camera_info" default="/camera/color/camera_info"/>
    <!-- hand_detection node -->
    <node name="detection_node"
        pkg="mocap_ros" type="detection_node.py"
        output="screen" >
    <remap from="~input_image" to="$(arg input_image)" />
    <remap from="~input_depth" to="$(arg input_depth)" />
    <remap from="~camera_info" to="$(arg camera_info)" />
    <rosparam subst_value="true" >
        device: $(arg device)
        publish_tf: $(arg publish_tf)
        threshold: $(arg threshold)
        with_mocap: $(arg with_mocap)
        detector_model: $(arg detector_model)
        mocap_model: $(arg mocap_model)
        visualize: $(arg visualize)
        render_type: $(arg render_type)
        rescale_factor: $(arg rescale_factor)
        margin: $(arg margin)
        scale: $(arg depth_scale)
        wrist_a: $(arg wrist_a)
        wrist_b: $(arg wrist_b)
    </rosparam>
    </node>
  </group>

  <node name="tip_arrow" pkg="mocap_ros" type="tip_arrow.py" output="screen" if="$(eval arrow)" />
</launch>
